{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420fd066-9299-4005-a0fc-5e547f0e9f9a",
   "metadata": {},
   "source": [
    "# Market Data Visulaizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460c162-6e37-421d-b7d3-9a6d69fa3f17",
   "metadata": {},
   "source": [
    "### Step 0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54295922-90da-4bc5-b5bd-e25cea31bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import interact\n",
    "\n",
    "# make plots a bit larger\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8060716-5213-4471-b0d5-18155804e0fb",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d638e0-a4e1-4ea5-bcc0-1e8583a831fc",
   "metadata": {},
   "source": [
    "### Step 1.1: Data Location & Available Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475c2140-6f4c-4fa4-92f5-63eda9ea31b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/raw/aapl_1d_2010-01-01_2025-08-16_yf.csv'),\n",
       " PosixPath('../data/raw/spy_1d_2020-01-01_2025-08-16_yf.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output .csv files in data/raw/..\n",
    "\n",
    "raw_dir = Path(\"../data/raw\")\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)  # ensure folder exists\n",
    "csv_files = sorted([p for p in raw_dir.glob(\"*.csv\")])\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in ../data/raw yet. Save one with fetch_data_yf.py first.\")\n",
    "csv_files[:5]  # preview list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa771d-f97d-400c-95c2-9a50d5bb704b",
   "metadata": {},
   "source": [
    "### Step 1.2: Choose & Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4251f936-d536-43c5-bfd4-ff0643c6e0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415c85a2c6cd4400a3497071aede1249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Primary', options=(('AAPL  |  1d  |  2010-01-01 → 2025-08-16  |  aapl_1d_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Easy loader: pick 2 CSVs from ../data/raw with widgets (robust names) ---\n",
    "\n",
    "import re, glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "RAW_DIR = Path(\"../data/raw\")\n",
    "\n",
    "# 1) list candidates\n",
    "files = sorted(glob.glob(str(RAW_DIR / \"*_yf.csv\")))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No *_yf.csv files found in {RAW_DIR}. Run your fetcher first.\")\n",
    "\n",
    "# 2) parse meta from filename\n",
    "pat = re.compile(\n",
    "    r\"(?P<sym>[a-z0-9_\\-]+)_(?P<intv>1[dwhm]|1wk|1mo|[0-9]+[mhdw])(?:_(?P<start>\\d{4}-\\d{2}-\\d{2})_(?P<end>\\d{4}-\\d{2}-\\d{2}))?_yf\\.csv$\",\n",
    "    re.I,\n",
    ")\n",
    "\n",
    "def parse_meta(path: str):\n",
    "    m = pat.search(Path(path).name)\n",
    "    if not m:\n",
    "        return None\n",
    "    return {\n",
    "        \"symbol\": m.group(\"sym\").upper(),\n",
    "        \"interval\": m.group(\"intv\"),\n",
    "        \"start\": m.group(\"start\"),\n",
    "        \"end\": m.group(\"end\"),\n",
    "        \"name\": Path(path).name,\n",
    "        \"path\": path,\n",
    "    }\n",
    "\n",
    "def label_for(path: str) -> str:\n",
    "    meta = parse_meta(path)\n",
    "    if meta:\n",
    "        s = meta[\"start\"] or \"?\"\n",
    "        e = meta[\"end\"] or \"?\"\n",
    "        return f\"{meta['symbol']}  |  {meta['interval']}  |  {s} → {e}  |  {meta['name']}\"\n",
    "    return f\"(unknown) | {Path(path).name}\"\n",
    "\n",
    "options = [(label_for(p), p) for p in files]\n",
    "\n",
    "# 3) widgets\n",
    "primary_dd = widgets.Dropdown(options=options, description=\"Primary\")\n",
    "bench_dd   = widgets.Dropdown(options=[(\"None (no benchmark)\", \"\")] + options, description=\"Benchmark\")\n",
    "load_btn   = widgets.Button(description=\"Load\", button_style=\"primary\")\n",
    "out        = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([primary_dd, bench_dd, load_btn, out]))\n",
    "\n",
    "# 4) loader helpers\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, parse_dates=[\"timestamp\"])\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).dt.tz_localize(None)\n",
    "    df = df.sort_values(\"timestamp\").drop_duplicates(\"timestamp\").reset_index(drop=True)\n",
    "    if \"Adj Close\" in df.columns and not df[\"Adj Close\"].isna().all():\n",
    "        df[\"close\"] = df[\"Adj Close\"]\n",
    "    return df\n",
    "\n",
    "# 5) click handler (uses unambiguous variable names)\n",
    "def on_load(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        global primary_df, primary_symbol, primary_interval, primary_meta\n",
    "        global bench_df, bench_symbol, bench_interval, bench_meta\n",
    "        # (optional) compatibility mirrors:\n",
    "        global df, symbol, interval\n",
    "\n",
    "        # primary\n",
    "        p_path = primary_dd.value\n",
    "        primary_meta = parse_meta(p_path) or {\"symbol\":\"UNKNOWN\",\"interval\":\"(unknown)\",\"name\":Path(p_path).name}\n",
    "        primary_symbol  = primary_meta[\"symbol\"]\n",
    "        primary_interval= primary_meta[\"interval\"]\n",
    "        primary_df      = load_csv(p_path)\n",
    "\n",
    "        print(f\"Primary: {primary_meta['name']}\")\n",
    "        print(f\"  rows={len(primary_df)}  range={primary_df['timestamp'].min().date()} → {primary_df['timestamp'].max().date()}  interval={primary_interval}\")\n",
    "\n",
    "        # (compatibility) mirror to df/symbol/interval so older cells still work\n",
    "        df = primary_df\n",
    "        symbol = primary_symbol\n",
    "        interval = primary_interval\n",
    "\n",
    "        # benchmark (optional)\n",
    "        bench_df = None\n",
    "        bench_symbol = None\n",
    "        bench_interval = None\n",
    "        bench_meta = None\n",
    "\n",
    "        if bench_dd.value:\n",
    "            b_path = bench_dd.value\n",
    "            bench_meta = parse_meta(b_path) or {\"symbol\":\"UNKNOWN\",\"interval\":\"(unknown)\",\"name\":Path(b_path).name}\n",
    "            bench_symbol   = bench_meta[\"symbol\"]\n",
    "            bench_interval = bench_meta[\"interval\"]\n",
    "            bench_df       = load_csv(b_path)\n",
    "\n",
    "            print(f\"Benchmark: {bench_meta['name']}\")\n",
    "            print(f\"  rows={len(bench_df)}  range={bench_df['timestamp'].min().date()} → {bench_df['timestamp'].max().date()}  interval={bench_interval}\")\n",
    "\n",
    "            if (primary_interval != bench_interval\n",
    "                and \"(unknown)\" not in (primary_interval, bench_interval)):\n",
    "                print(f\"⚠️ Intervals differ (primary={primary_interval}, benchmark={bench_interval}). \"\n",
    "                      \"Overlays will use date overlap only.\")\n",
    "\n",
    "            # report overlap\n",
    "            overlap = primary_df[[\"timestamp\"]].merge(bench_df[[\"timestamp\"]], on=\"timestamp\", how=\"inner\")\n",
    "            if overlap.empty:\n",
    "                print(\"⚠️ No overlapping dates between primary and benchmark.\")\n",
    "            else:\n",
    "                print(f\"Overlap: {overlap['timestamp'].min().date()} → {overlap['timestamp'].max().date()}  ({len(overlap)} rows)\")\n",
    "\n",
    "        print(\"\\n✅ Loaded. Variables:\")\n",
    "        print(\"   primary_df, primary_symbol, primary_interval\")\n",
    "        print(\"   bench_df,   bench_symbol,   bench_interval (None if not chosen)\")\n",
    "        print(\"   (compat) df, symbol, interval\\n\")\n",
    "\n",
    "load_btn.on_click(on_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c119c4-ca6f-452b-9303-85934f1f82f8",
   "metadata": {},
   "source": [
    "## Part 2: Initial EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843f49c-9b02-4d0b-9164-9f5222291b27",
   "metadata": {},
   "source": [
    "### Step 2.1: Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93402445-173b-4abe-8170-cde015645d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Robust OHLCV sanity check (order-safe & beginner-friendly) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sanity_check_prices(\n",
    "    df: pd.DataFrame,\n",
    "    name: str = \"asset\",\n",
    "    *,\n",
    "    interval: str | None = None,          # e.g., \"1d\", \"1h\" (optional; helps with heuristics)\n",
    "    first_rows: int = 3,                   # scan first N rows for odd gaps\n",
    "    open_close_pct_thresh: float = 0.08,   # 8% tolerance (higher by default for daily equities)\n",
    "    adj_close_scale_tol: float = 0.10,     # 10% tolerance between Close and Adj Close scales\n",
    "    echo_missing_breakdown: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Prints human-readable QA for an OHLCV DataFrame.\n",
    "    - Verifies required columns, monotonic timestamps, NaNs/dupes.\n",
    "    - Checks 'high >= low', non-negative prices, non-zero-only volume.\n",
    "    - Flags unusually large Open vs Close gaps in the first few rows.\n",
    "    - Warns if 'Adj Close' is on a different scale than 'close' (bad pipeline).\n",
    "    \"\"\"\n",
    "    msgs: list[str] = []\n",
    "\n",
    "    # 0) Required columns present?\n",
    "    required = {\"timestamp\", \"open\", \"high\", \"low\", \"close\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        msgs.append(f\"Missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    # 1) Timestamp sanity\n",
    "    if \"timestamp\" in df.columns:\n",
    "        if not np.issubdtype(df[\"timestamp\"].dtype, np.datetime64):\n",
    "            msgs.append(\"timestamp is not datetime64; consider parse_dates=['timestamp'] on read.\")\n",
    "        if df[\"timestamp\"].isna().any():\n",
    "            msgs.append(\"NaNs in timestamp.\")\n",
    "        dupes = int(df[\"timestamp\"].duplicated().sum())\n",
    "        if dupes > 0:\n",
    "            msgs.append(f\"{dupes} duplicated timestamps.\")\n",
    "        if not df[\"timestamp\"].is_monotonic_increasing:\n",
    "            msgs.append(\"timestamps not strictly increasing (unsorted and/or duplicates present).\")\n",
    "\n",
    "    # 2) NaNs in OHLCV\n",
    "    ohlcv_cols = [c for c in [\"open\", \"high\", \"low\", \"close\", \"volume\"] if c in df.columns]\n",
    "    nan_counts = df[ohlcv_cols].isna().sum()\n",
    "    if nan_counts.sum() > 0:\n",
    "        msgs.append(f\"NaNs in OHLCV: {nan_counts.to_dict()}\")\n",
    "\n",
    "    # 3) Price ordering / sign checks\n",
    "    if {\"high\", \"low\"} <= set(df.columns):\n",
    "        bad = int((df[\"high\"] < df[\"low\"]).sum())\n",
    "        if bad > 0:\n",
    "            msgs.append(f\"{bad} rows where high < low (corrupt).\")\n",
    "    for c in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        if c in df.columns:\n",
    "            neg = int((df[c] < 0).sum())\n",
    "            if neg > 0:\n",
    "                msgs.append(f\"{neg} negative values in '{c}' (invalid for prices).\")\n",
    "\n",
    "    # 4) Large Open vs Close gaps on the first few rows\n",
    "    #    Daily bars often have real overnight gaps. Use a *percentage* threshold and a higher default (8%).\n",
    "    if {\"open\", \"close\"} <= set(df.columns) and len(df) > 0:\n",
    "        n = min(first_rows, len(df))\n",
    "        oc = (df[\"open\"].head(n) - df[\"close\"].head(n)).abs() / df[\"close\"].head(n).replace(0, np.nan)\n",
    "        if oc.dropna().gt(open_close_pct_thresh).any():\n",
    "            pct = 100 * open_close_pct_thresh\n",
    "            hint = \"overnight gaps are common on daily bars\" if interval == \"1d\" else \"check file alignment\"\n",
    "            msgs.append(f\"Large open/close gap (>~{pct:.1f}%) in first {n} row(s) — {hint}.\")\n",
    "\n",
    "    # 5) Volume sanity\n",
    "    if \"volume\" in df.columns:\n",
    "        if df[\"volume\"].fillna(0).sum() == 0:\n",
    "            msgs.append(\"All volumes are zero (suspicious for stocks; normal for some crypto sources).\")\n",
    "        if (df[\"volume\"] < 0).any():\n",
    "            msgs.append(\"Negative volume values present (invalid).\")\n",
    "\n",
    "    # 6) Adj Close vs Close scale check\n",
    "    if \"Adj Close\" in df.columns and \"close\" in df.columns and not df[\"Adj Close\"].isna().all():\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            ratio = (df[\"Adj Close\"] / df[\"close\"]).replace([np.inf, -np.inf], np.nan).median()\n",
    "        if pd.notna(ratio) and abs(ratio - 1.0) > adj_close_scale_tol:\n",
    "            msgs.append(f\"'Adj Close' scale differs from 'close' (median ratio ≈ {ratio:.3f}). \"\n",
    "                        \"You may be mixing adjusted and unadjusted prices.\")\n",
    "\n",
    "    # 7) Print results\n",
    "    header = name.upper()\n",
    "    if msgs:\n",
    "        print(f\"⚠️  {header}: sanity warnings:\")\n",
    "        for m in msgs:\n",
    "            print(\"   -\", m)\n",
    "    else:\n",
    "        print(f\"✅ {header}: sanity check passed.\")\n",
    "\n",
    "    # Summary context\n",
    "    cols = list(df.columns)\n",
    "    print(f\"columns: {cols}\")\n",
    "    if \"timestamp\" in df.columns:\n",
    "        try:\n",
    "            print(f\"range:   {df['timestamp'].min().date()} → {df['timestamp'].max().date()}  | rows: {len(df)}\")\n",
    "        except Exception:\n",
    "            print(f\"rows: {len(df)}\")\n",
    "    if echo_missing_breakdown and ohlcv_cols:\n",
    "        print(\"missing values per column:\")\n",
    "        print(df.reindex(columns=ohlcv_cols).isna().sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468f0f2e-46fd-4929-a91f-fb4e79db0a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  AAPL: sanity warnings:\n",
      "   - Large open/close gap (>~8.0%) in first 3 row(s) — overnight gaps are common on daily bars.\n",
      "columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
      "range:   2010-01-04 → 2025-08-15  | rows: 3929\n",
      "missing values per column:\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n",
      "\n",
      "⚠️  SPY: sanity warnings:\n",
      "   - Large open/close gap (>~8.0%) in first 3 row(s) — overnight gaps are common on daily bars.\n",
      "columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
      "range:   2020-01-02 → 2025-08-15  | rows: 1413\n",
      "missing values per column:\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sanity_check_prices(primary_df, name=primary_symbol, interval=primary_interval)\n",
    "if bench_df is not None:\n",
    "    sanity_check_prices(bench_df, name=bench_symbol, interval=bench_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2242f-f6f5-4029-99d6-36ce1560a13c",
   "metadata": {},
   "source": [
    "### Step 2.2: Closing Price Chart\n",
    "\n",
    "The closing price is the last traded price of the asset for each interval (e.g., daily close).\n",
    "Plotting it over time gives an immediate sense of:\n",
    "\n",
    "\t• Whether the asset is trending upward, downward, or moving sideways.\n",
    "\t• Periods of sharp rises or crashes (e.g., during market events).\n",
    "\t• Long-term growth patterns versus short-term fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b17d915-52e4-479c-96e7-70a133ead8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c98c5288814e9ea4275d5531a3d8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='Overlay benchmark'), Checkbox(value=False, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Closing price plot (primary + optional benchmark with fair comparison) ---\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "\n",
    "def _align_on_dates(df1, df2, name_a=\"a\", name_b=\"b\"):\n",
    "    merged = (\n",
    "        df1[[\"timestamp\",\"close\"]].rename(columns={\"close\": f\"close_{name_a}\"})\n",
    "        .merge(\n",
    "            df2[[\"timestamp\",\"close\"]].rename(columns={\"close\": f\"close_{name_b}\"}),\n",
    "            on=\"timestamp\", how=\"inner\"\n",
    "        )\n",
    "        .sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    )\n",
    "    return merged.dropna()\n",
    "\n",
    "_have_bench = (\"bench_df\" in globals()) and (bench_df is not None)\n",
    "\n",
    "@interact(\n",
    "    show_bench = widgets.Checkbox(value=_have_bench, description=\"Overlay benchmark\"),\n",
    "    normalize  = widgets.Checkbox(value=False,       description=\"Normalize (rebase to 100)\"),\n",
    "    log_scale  = widgets.Checkbox(value=False,       description=\"Log scale (y)\")\n",
    ")\n",
    "def plot_close(show_bench, normalize, log_scale):\n",
    "    if \"df\" not in globals() or df is None or df.empty:\n",
    "        print(\"⚠️ Primary DataFrame `df` is missing or empty.\")\n",
    "        return\n",
    "\n",
    "    sym   = symbol.upper() if \"symbol\" in globals() else \"ASSET\"\n",
    "    bench = bench_symbol.upper() if (\"bench_symbol\" in globals() and bench_df is not None) else None\n",
    "    iv    = f\" ({interval})\" if \"interval\" in globals() else \"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11, 5))\n",
    "    title = f\"{sym} price{iv}\"\n",
    "\n",
    "    if show_bench and _have_bench and bench:\n",
    "        merged = _align_on_dates(df, bench_df, name_a=\"p\", name_b=\"b\")\n",
    "\n",
    "        if merged.empty:\n",
    "            print(\"⚠️ No overlapping dates with benchmark — cannot overlay.\")\n",
    "            ts, vals = df[\"timestamp\"], df[\"close\"].astype(float).ffill().bfill()\n",
    "            # Solo stats (return & CAGR)\n",
    "            years = (ts.iloc[-1] - ts.iloc[0]).days / 365.25\n",
    "            total_ret = vals.iloc[-1] / vals.iloc[0] - 1 if vals.iloc[0] != 0 else np.nan\n",
    "            cagr = (1 + total_ret)**(1/years) - 1 if years > 0 and np.isfinite(total_ret) else np.nan\n",
    "\n",
    "            if normalize:\n",
    "                vals = 100.0 * vals / vals.iloc[0]\n",
    "                ax.set_ylabel(\"index (100 = start)\")\n",
    "            else:\n",
    "                ax.set_ylabel(\"price\")\n",
    "\n",
    "            ax.plot(ts, vals, lw=2, label=f\"{sym} ({total_ret:+.1%}, CAGR {cagr:.2%})\")\n",
    "        else:\n",
    "            ts = merged[\"timestamp\"]\n",
    "            p  = merged[\"close_p\"].astype(float).to_numpy()\n",
    "            b  = merged[\"close_b\"].astype(float).to_numpy()\n",
    "\n",
    "            # returns & CAGR on overlap\n",
    "            p_ret = p[-1]/p[0] - 1 if p[0] != 0 else np.nan\n",
    "            b_ret = b[-1]/b[0] - 1 if b[0] != 0 else np.nan\n",
    "            years = (ts.iloc[-1] - ts.iloc[0]).days / 365.25\n",
    "            p_cagr = (p[-1]/p[0])**(1/years) - 1 if years > 0 and p[0] > 0 else np.nan\n",
    "            b_cagr = (b[-1]/b[0])**(1/years) - 1 if years > 0 and b[0] > 0 else np.nan\n",
    "\n",
    "            if normalize:\n",
    "                p = 100.0 * p / p[0]\n",
    "                b = 100.0 * b / b[0]\n",
    "                ax.set_ylabel(\"index (100 at start of overlap)\")\n",
    "            else:\n",
    "                ax.set_ylabel(\"price\")\n",
    "\n",
    "            ax.plot(ts, p, lw=2, label=f\"{sym} ({p_ret:+.1%}, CAGR {p_cagr:.2%})\")\n",
    "            ax.plot(ts, b, lw=1.6, alpha=0.95, label=f\"{bench} ({b_ret:+.1%}, CAGR {b_cagr:.2%})\")\n",
    "\n",
    "            title += f\" — vs {bench}\"\n",
    "            ax.text(0.01, 0.01,\n",
    "                    f\"Overlap: {ts.iloc[0].date()} → {ts.iloc[-1].date()}\",\n",
    "                    transform=ax.transAxes, fontsize=9, color=\"gray\")\n",
    "    else:\n",
    "        # Primary only (still show return & CAGR)\n",
    "        ts   = df[\"timestamp\"]\n",
    "        vals = df[\"close\"].astype(float).ffill().bfill()\n",
    "\n",
    "        years = (ts.iloc[-1] - ts.iloc[0]).days / 365.25\n",
    "        total_ret = vals.iloc[-1] / vals.iloc[0] - 1 if vals.iloc[0] != 0 else np.nan\n",
    "        cagr = (1 + total_ret)**(1/years) - 1 if years > 0 and np.isfinite(total_ret) else np.nan\n",
    "\n",
    "        if normalize:\n",
    "            vals = 100.0 * vals / vals.iloc[0]\n",
    "            ax.set_ylabel(\"index (100 = start)\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"price\")\n",
    "\n",
    "        ax.plot(ts, vals, lw=2, label=f\"{sym} ({total_ret:+.1%}, CAGR {cagr:.2%})\")\n",
    "\n",
    "    # Cosmetics\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"date\")\n",
    "    if log_scale:\n",
    "        ax.set_yscale(\"log\")\n",
    "    ax.grid(alpha=0.3, linestyle=\"--\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "    fig.autofmt_xdate(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b020b-8c19-4009-b50f-cdd29be910ca",
   "metadata": {},
   "source": [
    "### Step 2.3: Trading Volume\n",
    "\n",
    "The volume chart shows how much of the asset is traded over time. This matters because large price moves on high volume indicate stronger conviction (more participants), while moves on low volume can be misleading.\n",
    "\n",
    "What’s shown here:\n",
    "\n",
    "\t• Blue line = raw daily trading volume.\n",
    "\t• Orange line = rolling average of volume (default = 20 bars ≈ one month for daily data).\n",
    "    • X-bar average” means the average over the last X data points. One bar = one row of your dataset (daily = 1 day, hourly = 1 hour, weekly = 1 week). So a  20-bar average on daily data ≈ 1 month of trading.\n",
    "\t• This helps you compare today’s activity to “typical” recent levels.\n",
    "\t• You can adjust the window interactively depending on your data frequency (daily, weekly, hourly).\n",
    "\t• Red circles = top-5 spike days (unusually high activity).\n",
    "\n",
    "How to interpret:\n",
    "\n",
    "\t• Spikes far above the average = event days (earnings, splits, news).\n",
    "\t• Persistent rising average = growing participation.\n",
    "\t• Very low volume = quieter regimes, where signals may be less reliable.\n",
    "\n",
    "Typical ranges for the rolling average:\n",
    "\n",
    "\t• Daily data → 10–30 bars (≈ 2–6 weeks)\n",
    "\t• Weekly data → 4–12 bars (≈ 1–3 months)\n",
    "\t• Hourly data → 24–168 bars (≈ 1–7 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e87b4e1-cbf5-4fdf-9995-3aa8aeba3deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e66348895ff4b2cb41cf2074a00d1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='Avg window', min=5, step=5), IntSlider(value=5, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_volume(avg_window, topn, show_bench)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Trading Volume Visualization (bars + rolling averages + spikes, with overlay) ---\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Sliders + checkbox\n",
    "avg_slider   = widgets.IntSlider(value=20, min=5, max=100, step=5, description=\"Avg window\")\n",
    "topn_slider  = widgets.IntSlider(value=5,  min=3, max=20,  step=1, description=\"Mark top-N\")\n",
    "bench_check  = widgets.Checkbox(value=(bench_df is not None), description=\"Overlay benchmark (overlap only)\")\n",
    "\n",
    "def plot_volume(avg_window, topn, show_bench):\n",
    "    fig, axes = plt.subplots(\n",
    "        2 if (show_bench and bench_df is not None) else 1,\n",
    "        1,\n",
    "        figsize=(12, 8 if (show_bench and bench_df is not None) else 5),\n",
    "        sharex=False\n",
    "    )\n",
    "\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = [axes]\n",
    "\n",
    "    # --- Primary asset ---\n",
    "    vol_p = df[\"volume\"] / 1e6\n",
    "    ax1 = axes[0]\n",
    "    ax1.bar(df[\"timestamp\"], vol_p, width=1.0, alpha=0.3, label=f\"{symbol.upper()} volume\")\n",
    "    ax1.plot(df[\"timestamp\"], vol_p.rolling(avg_window).mean(),\n",
    "             lw=2, label=f\"{symbol.upper()} {avg_window}-bar avg\")\n",
    "\n",
    "    top_p = vol_p.nlargest(topn)\n",
    "    ax1.scatter(df.loc[top_p.index, \"timestamp\"], top_p.values,\n",
    "                color=\"red\", s=50, zorder=5, label=f\"{symbol.upper()} top-{topn}\")\n",
    "\n",
    "    ax1.set_title(f\"{symbol.upper()} — Trading volume ({interval})\")\n",
    "    ax1.set_ylabel(\"millions of shares\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "    # --- Benchmark overlay (only if overlap exists) ---\n",
    "    if show_bench and bench_df is not None:\n",
    "        merged = df[[\"timestamp\",\"volume\"]].merge(\n",
    "            bench_df[[\"timestamp\",\"volume\"]], on=\"timestamp\", how=\"inner\", suffixes=(\"_p\",\"_b\")\n",
    "        )\n",
    "        if merged.empty:\n",
    "            print(\"⚠️ No overlapping dates with benchmark.\")\n",
    "        else:\n",
    "            ts = merged[\"timestamp\"]\n",
    "            vol_p = merged[\"volume_p\"] / 1e6\n",
    "            vol_b = merged[\"volume_b\"] / 1e6\n",
    "            ax2 = axes[1]\n",
    "\n",
    "            # Bars\n",
    "            ax2.bar(ts, vol_p, width=1.0, alpha=0.3, label=f\"{symbol.upper()} volume\")\n",
    "            ax2.bar(ts, vol_b, width=1.0, alpha=0.3, label=f\"{bench_symbol.upper()} volume\")\n",
    "\n",
    "            # Rolling averages\n",
    "            ax2.plot(ts, vol_p.rolling(avg_window).mean(),\n",
    "                     lw=2, label=f\"{symbol.upper()} {avg_window}-bar avg\")\n",
    "            ax2.plot(ts, vol_b.rolling(avg_window).mean(),\n",
    "                     lw=2, label=f\"{bench_symbol.upper()} {avg_window}-bar avg\")\n",
    "\n",
    "            # Top spikes\n",
    "            top_p = vol_p.nlargest(topn)\n",
    "            top_b = vol_b.nlargest(topn)\n",
    "            ax2.scatter(ts.iloc[top_p.index], top_p.values,\n",
    "                        color=\"red\", s=40, label=f\"{symbol.upper()} top-{topn}\")\n",
    "            ax2.scatter(ts.iloc[top_b.index], top_b.values,\n",
    "                        color=\"orange\", s=40, label=f\"{bench_symbol.upper()} top-{topn}\")\n",
    "\n",
    "            ax2.set_title(f\"Volume overlay — {symbol.upper()} vs {bench_symbol.upper()}  |  \"\n",
    "                          f\"Overlap: {ts.min().date()} → {ts.max().date()}\")\n",
    "            ax2.set_ylabel(\"millions of shares\")\n",
    "            ax2.set_xlabel(\"date\")\n",
    "            ax2.legend()\n",
    "            ax2.grid(alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "    # Cosmetics for all axes\n",
    "    for ax in axes:\n",
    "        ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget\n",
    "widgets.interact(\n",
    "    plot_volume,\n",
    "    avg_window=avg_slider,\n",
    "    topn=topn_slider,\n",
    "    show_bench=bench_check\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108945c9-c79c-4b68-a19f-ce8190965602",
   "metadata": {},
   "source": [
    "### Step 2.4: Cumulative Returns with Risk Metrics\n",
    "\n",
    "This chart shows how an initial investment would have grown (or shrunk) over time if you bought and held the asset.  \n",
    "It also adds risk insights like **drawdowns** (losses from peaks) and the **CAGR** (average annual growth).\n",
    "\n",
    "What it does:\n",
    "- Start with your chosen initial investment (e.g., $1,000).\n",
    "- Each day, the price moves up or down. We calculate the daily return (% change from yesterday).\n",
    "- Returns are **compounded** — every gain or loss builds on the prior day’s value.\n",
    "- This creates a portfolio curve showing how your money evolves over time.\n",
    "- On top of growth, we shade drawdown periods (the drops from prior peaks) and calculate key stats.\n",
    "\n",
    "Key terms explained:\n",
    "- **Compounded Growth**: Returns multiply over time. Example → +10% then –10% leaves you at –1%, not 0.\n",
    "- **Drawdown**: How much you fall from the latest peak. Big drawdowns = rough ride for investors.\n",
    "- **CAGR (Compound Annual Growth Rate)**: The “smoothed” yearly growth rate that would turn your start value into the final value, as if it grew steadily.\n",
    "- **Max Drawdown**: The worst % drop from a peak during the period — a key risk measure.\n",
    "\n",
    "How to read the chart:\n",
    "- **Purple line** = portfolio growth (buy & hold performance).\n",
    "- **Shaded areas** = drawdowns (losses from peaks).\n",
    "- **Metrics box** (bottom-right) = Final $, total % return, CAGR, and Max Drawdown.\n",
    "- **Steady upward slope** → consistent growth.  \n",
    "- **Sharp drops** → crashes or corrections.  \n",
    "- **Flat periods** → stagnation.  \n",
    "- **Start date slider** → shows how entry timing changes your outcome.  \n",
    "- **Log scale toggle** → makes exponential growth periods easier to compare.\n",
    "\n",
    "Finance note ⚖️:\n",
    "- Using **Close prices** = raw market performance (ignores dividends).  \n",
    "- Using **Adjusted Close** = assumes dividends reinvested and stock splits accounted for → truer “investor returns.”  \n",
    "- That’s why numbers here may differ from Google/Yahoo charts, which usually use Adjusted Close.\n",
    "\n",
    "👉 Example:  \n",
    "If you invested $1,000 in Apple in 2010 and it grew to ~$36,000 by 2025, that’s a +3500% return.  \n",
    "The CAGR would be ~24% per year — meaning, on average, it’s like compounding 24% every year, even though the actual path had big ups and downs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7bc38a-1996-4a42-8e44-99edbd722b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110f0db9afc74313b6c4118d5f9476bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1000, description='Invest $', max=20000, min=100, step=100), SelectionSl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _get_bench():\n",
    "    \"\"\"Return (bench_df, bench_label) if a usable benchmark is in memory; else (None, None).\"\"\"\n",
    "    bdf = globals().get(\"bench_df\", None)\n",
    "    if isinstance(bdf, pd.DataFrame) and not bdf.empty:\n",
    "        return bdf, globals().get(\"bench_symbol\", \"Benchmark\")\n",
    "    return None, None\n",
    "\n",
    "# Date slider options (built from primary df)\n",
    "date_options = [(ts.strftime(\"%Y-%m-%d\"), ts) for ts in df[\"timestamp\"].unique()]\n",
    "default_date = df[\"timestamp\"].iloc[0]\n",
    "\n",
    "@interact(\n",
    "    invest=widgets.IntSlider(value=1000, min=100, max=20000, step=100, description=\"Invest $\"),\n",
    "    start=widgets.SelectionSlider(options=date_options, value=default_date,\n",
    "                                  description=\"Start\", continuous_update=True),\n",
    "    log_scale=widgets.Checkbox(value=False, description=\"Log scale (y)\"),\n",
    "    show_stats=widgets.Checkbox(value=True, description=\"Show stats\"),\n",
    "    # default reflects what's in memory *right now*\n",
    "    show_bench=widgets.Checkbox(value=(_get_bench()[0] is not None), description=\"Overlay benchmark\")\n",
    ")\n",
    "def plot_cumulative(invest, start, log_scale, show_stats, show_bench):\n",
    "    # Slice\n",
    "    sub = df[df[\"timestamp\"] >= start].copy()\n",
    "    if sub.empty:\n",
    "        print(\"No data from this start date.\")\n",
    "        return\n",
    "\n",
    "    # Returns & compounding\n",
    "    sub[\"ret\"] = sub[\"close\"].pct_change().fillna(0.0)\n",
    "    sub[\"cum\"] = (1.0 + sub[\"ret\"]).cumprod()\n",
    "    sub[\"portfolio\"] = invest * sub[\"cum\"]\n",
    "\n",
    "    # Audit & CAGR\n",
    "    cum_ratio_end = sub[\"close\"].iloc[-1] / sub[\"close\"].iloc[0]\n",
    "    if abs(sub[\"cum\"].iloc[-1] - cum_ratio_end) > 1e-3:\n",
    "        print(\"⚠️ Cumprod and price-ratio disagree. Check gaps/NaNs or whether 'close' is adjusted.\")\n",
    "    years = (sub[\"timestamp\"].iloc[-1] - sub[\"timestamp\"].iloc[0]).days / 365.25\n",
    "    cagr  = cum_ratio_end**(1/years) - 1 if years > 0 else float(\"nan\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(sub[\"timestamp\"], sub[\"portfolio\"], color=\"purple\", lw=2, label=f\"Growth of ${invest:,}\")\n",
    "\n",
    "    # Drawdown shading\n",
    "    runmax   = sub[\"portfolio\"].cummax()\n",
    "    drawdown = sub[\"portfolio\"] / runmax - 1.0\n",
    "    ax.fill_between(sub[\"timestamp\"], sub[\"portfolio\"], runmax,\n",
    "                    where=sub[\"portfolio\"] < runmax, alpha=0.15, label=\"Drawdown\")\n",
    "\n",
    "    # Worst DD band & label (only when stats on)\n",
    "    worst_dd = float(drawdown.min()) if np.isfinite(drawdown.min()) else 0.0\n",
    "    if show_stats and np.isfinite(worst_dd) and worst_dd < 0:\n",
    "        dd_vals = drawdown.values\n",
    "        trough_idx = int(np.argmin(dd_vals))\n",
    "        runmax_vals = runmax.values\n",
    "        peak_idx = int(np.argmax(runmax_vals[:trough_idx+1]))\n",
    "        t0 = sub[\"timestamp\"].iloc[peak_idx]\n",
    "        t1 = sub[\"timestamp\"].iloc[trough_idx]\n",
    "        ax.axvspan(t0, t1, color=\"red\", alpha=0.08, zorder=0)\n",
    "        ax.text(sub[\"timestamp\"].iloc[0], ax.get_ylim()[1]*0.98,\n",
    "                f\"Worst DD: {worst_dd:.1%}  ({t0.date()} → {t1.date()})\",\n",
    "                fontsize=9, color=\"#b04040\", va=\"top\")\n",
    "\n",
    "    # Start / End\n",
    "    start_val = float(sub[\"portfolio\"].iloc[0])\n",
    "    end_val   = float(sub[\"portfolio\"].iloc[-1])\n",
    "    pct_total = (end_val / start_val - 1.0) * 100.0\n",
    "    ax.scatter(sub[\"timestamp\"].iloc[0], start_val, color=\"green\", s=60, zorder=3, label=f\"Start: ${start_val:,.2f}\")\n",
    "    ax.scatter(sub[\"timestamp\"].iloc[-1], end_val,   color=\"red\",   s=60, zorder=3, label=f\"End: ${end_val:,.2f}\")\n",
    "    ax.text(sub[\"timestamp\"].iloc[-1], end_val, f\"  Final: ${end_val:,.2f}  ({pct_total:+.1f}%)\",\n",
    "            va=\"center\", fontsize=10, color=\"red\")\n",
    "\n",
    "    # Benchmark overlay (look up the live global every time)\n",
    "    bench_cagr = None\n",
    "    if show_bench:\n",
    "        bdf, blabel = _get_bench()\n",
    "        if bdf is None:\n",
    "            # Gentle hint on the chart rather than a noisy print\n",
    "            ax.text(0.99, 0.98, \"No benchmark loaded\", transform=ax.transAxes,\n",
    "                    ha=\"right\", va=\"top\", fontsize=9, color=\"gray\")\n",
    "        else:\n",
    "            bsub = bdf[bdf[\"timestamp\"] >= start]\n",
    "            merged = sub[[\"timestamp\",\"close\"]].rename(columns={\"close\":\"asset\"}).merge(\n",
    "                bsub.rename(columns={\"close\":\"bench\"}), on=\"timestamp\", how=\"inner\"\n",
    "            )\n",
    "            if not merged.empty:\n",
    "                asset_ix = merged[\"asset\"] / merged[\"asset\"].iloc[0]\n",
    "                bench_ix = merged[\"bench\"] / merged[\"bench\"].iloc[0]\n",
    "                ax.plot(merged[\"timestamp\"], invest * bench_ix, lw=1.8, alpha=0.9, label=blabel)\n",
    "                if years > 0:\n",
    "                    bench_cagr = bench_ix.iloc[-1]**(1/years) - 1\n",
    "\n",
    "    # Metrics box\n",
    "    if show_stats:\n",
    "        lines = [\n",
    "            f\"Final: ${end_val:,.0f}\",\n",
    "            f\"Total: {pct_total:+.1f}%\",\n",
    "            f\"CAGR:  {cagr:.2%}\",\n",
    "            f\"Max DD: {worst_dd:.1%}\",\n",
    "        ]\n",
    "        if bench_cagr is not None and np.isfinite(bench_cagr):\n",
    "            lines.append(f\"vs {globals().get('bench_symbol','Bench')} CAGR: {(cagr - bench_cagr):+.2%} (Δ)\")\n",
    "        ax.text(0.985, 0.02, \"\\n\".join(lines),\n",
    "                transform=ax.transAxes, ha=\"right\", va=\"bottom\",\n",
    "                fontsize=9, bbox=dict(facecolor=\"white\", alpha=0.85, boxstyle=\"round,pad=0.3\"))\n",
    "\n",
    "    # Cosmetics\n",
    "    title_tag = \"Adj Close\" if (\"Adj Close\" in df.columns and df[\"close\"].equals(df[\"Adj Close\"])) else \"Close\"\n",
    "    ttl = f\"Cumulative Returns (Compounded Growth)\\n{title_tag}; CAGR: {cagr:.2%}\"\n",
    "    if bench_cagr is not None and np.isfinite(bench_cagr):\n",
    "        ttl += f\" | {globals().get('bench_symbol','Bench')} CAGR: {bench_cagr:.2%}\"\n",
    "    ax.set_title(ttl)\n",
    "    ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Portfolio Value ($)\")\n",
    "    if log_scale: ax.set_yscale(\"log\")\n",
    "    ax.grid(alpha=0.3, linestyle=\"--\"); ax.legend(loc=\"best\")\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "    ax.text(0.01, 0.01, f\"Source: {title_tag} | Rebased from {sub['timestamp'].iloc[0].date()}\",\n",
    "            transform=ax.transAxes, fontsize=9, color=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e756f-e44d-458e-8930-64edb71a236d",
   "metadata": {},
   "source": [
    "### Cumulative + DCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431d0eda-c514-4f4f-a5f8-d3864c31951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61eba66476c2428fa4bffb6b50be329a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Start', options=(('2010-01-04', Timestamp('2010-01-04 00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cumulative returns with DCA (lump sum + recurring contributions) ---\n",
    "# What this cell does:\n",
    "# - Lets you choose an initial investment AND a recurring contribution (e.g., $100/month)\n",
    "# - Snaps each contribution to the next available trading day in your data\n",
    "# - Buys fractional shares at those dates; portfolio value = shares * price over time\n",
    "# - Shows Total Invested, Final Value, P/L, Multiple, and money-weighted return (XIRR)\n",
    "# - Optional benchmark overlay runs the EXACT same contribution schedule on the benchmark\n",
    "# - Works with your existing df (primary) and optional bench_df prepared earlier\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ---------- helpers ----------\n",
    "\n",
    "def _get_bench():\n",
    "    \"\"\"Return (bench_df, bench_label) if a usable benchmark is in memory; else (None, None).\"\"\"\n",
    "    bdf = globals().get(\"bench_df\", None)\n",
    "    if isinstance(bdf, pd.DataFrame) and not bdf.empty:\n",
    "        return bdf, globals().get(\"bench_symbol\", \"Benchmark\").upper()\n",
    "    return None, None\n",
    "\n",
    "def _next_trading_on_or_after(ts_series: pd.Series, d: pd.Timestamp):\n",
    "    \"\"\"Find the first index in ts_series where timestamp >= d. Returns index or None.\"\"\"\n",
    "    i = ts_series.searchsorted(d)\n",
    "    if i >= len(ts_series):\n",
    "        return None\n",
    "    return int(i)\n",
    "\n",
    "def _build_schedule(start_ts: pd.Timestamp,\n",
    "                    end_ts:   pd.Timestamp,\n",
    "                    freq:     str = \"M\",\n",
    "                    day:      int = 1):\n",
    "    \"\"\"\n",
    "    Build nominal contribution dates between start and end:\n",
    "    - freq: 'M' (monthly), 'W' (weekly), 'Q' (quarterly)\n",
    "    - day: day-of-month (1..28) used for monthly/quarterly anchors\n",
    "    \"\"\"\n",
    "    if freq == \"W\":\n",
    "        dates = pd.date_range(start_ts.normalize(), end_ts.normalize(), freq=\"W\")\n",
    "    else:\n",
    "        # monthly/quarterly: use month starts then shift to desired day\n",
    "        base = pd.date_range(start_ts.normalize(), end_ts.normalize(),\n",
    "                             freq=(\"QS\" if freq == \"Q\" else \"MS\"))\n",
    "        # clamp day to [1,28] to avoid month-end issues\n",
    "        day = int(np.clip(day, 1, 28))\n",
    "        dates = []\n",
    "        for d in base:\n",
    "            dates.append(pd.Timestamp(year=d.year, month=d.month, day=day))\n",
    "        dates = pd.to_datetime(dates)\n",
    "    # ensure we don't include the very first date if it's exactly the start (we'll buy lump-sum at t0)\n",
    "    return dates[dates > start_ts.normalize()]\n",
    "\n",
    "def _simulate_dca(sub: pd.DataFrame,\n",
    "                  initial: float,\n",
    "                  contrib: float,\n",
    "                  freq:    str = \"M\",\n",
    "                  day:     int = 1):\n",
    "    \"\"\"\n",
    "    Vectorized DCA on a single price series (sub with columns timestamp, close).\n",
    "    Returns: portfolio Series, shares Series, contributions DataFrame, totals dict.\n",
    "    \"\"\"\n",
    "    sub = sub.copy()\n",
    "    ts  = sub[\"timestamp\"].reset_index(drop=True)\n",
    "    px  = sub[\"close\"].astype(float).reset_index(drop=True)\n",
    "    n   = len(sub)\n",
    "    buys_shares = np.zeros(n, dtype=float)\n",
    "\n",
    "    # Initial buy at first available bar\n",
    "    if n == 0:\n",
    "        raise ValueError(\"Empty sub-series for DCA simulation.\")\n",
    "    buys_shares[0] += (initial / px.iloc[0]) if px.iloc[0] > 0 else 0.0\n",
    "\n",
    "    # Build nominal schedule and snap to trading days\n",
    "    sched_nom = _build_schedule(ts.iloc[0], ts.iloc[-1], freq=freq, day=day)\n",
    "    snapped = []\n",
    "    for d in sched_nom:\n",
    "        j = _next_trading_on_or_after(ts, d)\n",
    "        if j is not None:\n",
    "            snapped.append((j, ts.iloc[j]))\n",
    "    snapped = list(dict.fromkeys(snapped))  # dedupe if multiple map to same bar\n",
    "\n",
    "    # Add recurring buys\n",
    "    for j, _dt in snapped:\n",
    "        if px.iloc[j] > 0:\n",
    "            buys_shares[j] += contrib / px.iloc[j]\n",
    "\n",
    "    shares = pd.Series(buys_shares).cumsum()\n",
    "    portfolio = shares * px\n",
    "\n",
    "    # Cashflow table for XIRR (negative = cash out, positive = cash in at the *end*)\n",
    "    cashflows = []\n",
    "    cashflows.append((ts.iloc[0].to_pydatetime(), -float(initial)))\n",
    "    for j, _dt in snapped:\n",
    "        cashflows.append((ts.iloc[j].to_pydatetime(), -float(contrib)))\n",
    "    cashflows.append((ts.iloc[-1].to_pydatetime(), float(portfolio.iloc[-1])))\n",
    "\n",
    "    totals = {\n",
    "        \"total_invested\": float(initial + contrib * len(snapped)),\n",
    "        \"final_value\":    float(portfolio.iloc[-1]),\n",
    "        \"contrib_count\":  int(len(snapped))\n",
    "    }\n",
    "    return portfolio, shares, pd.DataFrame({\"timestamp\":[d for _,d in snapped]}), totals, cashflows\n",
    "\n",
    "def _xirr(cashflows, guess=0.15, max_iter=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Simple XIRR solver via Newton-Raphson.\n",
    "    cashflows: list of (datetime, amount) with positives = inflows (final value), negatives = investments\n",
    "    Returns annualized rate, or np.nan if it fails.\n",
    "    \"\"\"\n",
    "    if len(cashflows) < 2:\n",
    "        return np.nan\n",
    "    t0 = cashflows[0][0]\n",
    "    def npv(rate):\n",
    "        v = 0.0\n",
    "        for dt, amt in cashflows:\n",
    "            y = (dt - t0).days / 365.25\n",
    "            v += amt / ((1 + rate) ** y)\n",
    "        return v\n",
    "    def dnpv(rate):\n",
    "        v = 0.0\n",
    "        for dt, amt in cashflows:\n",
    "            y = (dt - t0).days / 365.25\n",
    "            if rate == -1:  # avoid blow-up\n",
    "                return np.inf\n",
    "            v += -y * amt / ((1 + rate) ** (y + 1))\n",
    "        return v\n",
    "    r = guess\n",
    "    for _ in range(max_iter):\n",
    "        f = npv(r)\n",
    "        df = dnpv(r)\n",
    "        if df == 0:\n",
    "            return np.nan\n",
    "        r_new = r - f/df\n",
    "        if abs(r_new - r) < tol:\n",
    "            return r_new\n",
    "        r = r_new\n",
    "    return np.nan\n",
    "\n",
    "# ---------- interactive plot ----------\n",
    "\n",
    "# Date slider from df\n",
    "date_options = [(ts.strftime(\"%Y-%m-%d\"), ts) for ts in df[\"timestamp\"].unique()]\n",
    "default_date = df[\"timestamp\"].iloc[0]\n",
    "\n",
    "@interact(\n",
    "    start       = widgets.SelectionSlider(options=date_options, value=default_date, description=\"Start\", continuous_update=True),\n",
    "    initial_usd = widgets.IntSlider(value=1000, min=0, max=20000, step=100, description=\"Initial ($)\"),\n",
    "    contrib_usd = widgets.IntSlider(value=100,  min=0, max=5000,  step=25,  description=\"Contrib ($)\"),\n",
    "    freq        = widgets.Dropdown(options=[(\"Monthly\",\"M\"), (\"Weekly\",\"W\"), (\"Quarterly\",\"Q\")], value=\"M\", description=\"Frequency\"),\n",
    "    day_of_mo   = widgets.IntSlider(value=1, min=1, max=28, step=1, description=\"Day (M/Q)\"),\n",
    "    log_scale   = widgets.Checkbox(value=False, description=\"Log scale (y)\"),\n",
    "    show_bench  = widgets.Checkbox(value=(_get_bench()[0] is not None), description=\"Overlay benchmark\"),\n",
    "    show_stats  = widgets.Checkbox(value=True, description=\"Show stats\")\n",
    ")\n",
    "def plot_cumulative_dca(start, initial_usd, contrib_usd, freq, day_of_mo, log_scale, show_bench, show_stats):\n",
    "    # Primary slice\n",
    "    sub = df[df[\"timestamp\"] >= start][[\"timestamp\",\"close\"]].copy()\n",
    "    if sub.empty:\n",
    "        print(\"No data from this start date.\")\n",
    "        return\n",
    "\n",
    "    # Simulate DCA on primary\n",
    "    port, shares, sched_df, totals, cashflows = _simulate_dca(\n",
    "        sub, initial=initial_usd, contrib=contrib_usd, freq=freq, day=day_of_mo\n",
    "    )\n",
    "    # Price-only CAGR (for reference)\n",
    "    years = (sub[\"timestamp\"].iloc[-1] - sub[\"timestamp\"].iloc[0]).days / 365.25\n",
    "    price_mult = float(sub[\"close\"].iloc[-1] / sub[\"close\"].iloc[0])\n",
    "    cagr_price = (price_mult**(1/years) - 1) if years > 0 else np.nan\n",
    "    # Money-weighted return\n",
    "    xirr = _xirr(cashflows)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(sub[\"timestamp\"], port, color=\"purple\", lw=2, label=f\"Portfolio (DCA)\")\n",
    "\n",
    "    # Drawdown shading\n",
    "    runmax   = port.cummax()\n",
    "    drawdown = port / runmax - 1.0\n",
    "    ax.fill_between(sub[\"timestamp\"], port, runmax, where=(port < runmax), alpha=0.15, label=\"Drawdown\")\n",
    "\n",
    "    # Mark contribution dots (optional: big markers so users see schedule)\n",
    "    if len(sched_df):\n",
    "        # snap contributions to plotted values\n",
    "        contrib_idx = sub[\"timestamp\"].searchsorted(sched_df[\"timestamp\"].values)\n",
    "        contrib_idx = contrib_idx[contrib_idx < len(sub)]\n",
    "        ax.scatter(sub[\"timestamp\"].iloc[contrib_idx], port.iloc[contrib_idx],\n",
    "                   s=20, color=\"gray\", alpha=0.6, label=\"Contrib points\")\n",
    "\n",
    "    # Start/End markers + final label\n",
    "    ax.scatter(sub[\"timestamp\"].iloc[0], port.iloc[0], color=\"green\", s=60, zorder=3, label=f\"Start: ${port.iloc[0]:,.2f}\")\n",
    "    ax.scatter(sub[\"timestamp\"].iloc[-1], port.iloc[-1], color=\"red\", s=60, zorder=3, label=f\"End: ${port.iloc[-1]:,.2f}\")\n",
    "    ax.text(sub[\"timestamp\"].iloc[-1], port.iloc[-1],\n",
    "            f\"  Final: ${port.iloc[-1]:,.2f}\", va=\"center\", fontsize=10, color=\"red\")\n",
    "\n",
    "    # Optional: run the same schedule on the benchmark\n",
    "    bench_xirr = None\n",
    "    bench_label = None\n",
    "    if show_bench:\n",
    "        bdf, bench_label = _get_bench()\n",
    "        if bdf is None:\n",
    "            ax.text(0.99, 0.98, \"No benchmark loaded\", transform=ax.transAxes,\n",
    "                    ha=\"right\", va=\"top\", fontsize=9, color=\"gray\")\n",
    "        else:\n",
    "            bsub = bdf[bdf[\"timestamp\"] >= start][[\"timestamp\",\"close\"]].copy()\n",
    "            if not bsub.empty:\n",
    "                b_port, b_shares, b_sched_df, b_totals, b_cashflows = _simulate_dca(\n",
    "                    bsub, initial=initial_usd, contrib=contrib_usd, freq=freq, day=day_of_mo\n",
    "                )\n",
    "                ax.plot(bsub[\"timestamp\"], b_port, lw=1.8, alpha=0.9, label=f\"{bench_label} (DCA)\")\n",
    "                bench_xirr = _xirr(b_cashflows)\n",
    "\n",
    "    # Cosmetics\n",
    "    title_tag = \"Adj Close\" if (\"Adj Close\" in df.columns and df[\"close\"].equals(df.get(\"Adj Close\", df[\"close\"]))) else \"Close\"\n",
    "    title = f\"Cumulative Returns (DCA: lump + recurring)\\n{title_tag}; Price CAGR: {cagr_price:.2%} | XIRR: {xirr:.2%}\"\n",
    "    if bench_xirr is not None and np.isfinite(bench_xirr):\n",
    "        title += f\" | {bench_label} XIRR: {bench_xirr:.2%}\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Portfolio Value ($)\")\n",
    "    if log_scale: ax.set_yscale(\"log\")\n",
    "    ax.grid(alpha=0.3, linestyle=\"--\")\n",
    "    ax.legend(loc=\"upper left\", frameon=True)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "    ax.text(0.01, 0.01,\n",
    "            f\"Invested: ${totals['total_invested']:,.0f}  |  Contribs: {totals['contrib_count']}  |  Multiple: {totals['final_value']/max(totals['total_invested'],1):.2f}×\",\n",
    "            transform=ax.transAxes, fontsize=9, color=\"gray\")\n",
    "\n",
    "    # Optional stats box with drawdown and P/L\n",
    "    if show_stats:\n",
    "        max_dd = float(drawdown.min()) if np.isfinite(drawdown.min()) else 0.0\n",
    "        pnl = totals[\"final_value\"] - totals[\"total_invested\"]\n",
    "        box = (f\"Final: ${totals['final_value']:,.0f}\\n\"\n",
    "               f\"Total Invested: ${totals['total_invested']:,.0f}\\n\"\n",
    "               f\"P/L: {pnl:+,.0f}\\n\"\n",
    "               f\"Max DD: {max_dd:.1%}\")\n",
    "        ax.text(0.985, 0.02, box,\n",
    "                transform=ax.transAxes, ha=\"right\", va=\"bottom\",\n",
    "                fontsize=9, bbox=dict(facecolor=\"white\", alpha=0.85, boxstyle=\"round,pad=0.3\"))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077d47f-f618-45f5-801a-58ef56c59954",
   "metadata": {},
   "source": [
    "### Step 2.5: Candle Stick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e596bb0a-dd94-47cf-89c8-9b860e90e138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9926f8f3313428d869503e31a02d59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Candles', layout=Layout(width='210px'), options=(('Origina…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e135472cd8f454faa3dee368a3cf70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2076f923b6e345e08a5cf874ecda5eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Pro Candles: resample, x-unified hover, MA, range tools, separate benchmark ===\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _prep(_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = _df.copy()\n",
    "    d[\"timestamp\"] = pd.to_datetime(d[\"timestamp\"]).dt.tz_localize(None)\n",
    "    d = d.sort_values(\"timestamp\").drop_duplicates(\"timestamp\").reset_index(drop=True)\n",
    "    if \"Adj Close\" in d.columns and not d[\"Adj Close\"].isna().all():\n",
    "        d[\"close\"] = d[\"Adj Close\"]\n",
    "    return d\n",
    "\n",
    "def _resample_ohlcv(d: pd.DataFrame, rule: str) -> pd.DataFrame:\n",
    "    \"\"\"rule in {'Original','W','M'}\"\"\"\n",
    "    if rule in (None, \"\", \"Original\", \"D\"):\n",
    "        return d.copy()\n",
    "    agg = {\"open\":\"first\",\"high\":\"max\",\"low\":\"min\",\"close\":\"last\"}\n",
    "    if \"volume\" in d.columns:\n",
    "        agg[\"volume\"] = \"sum\"\n",
    "    s = d.set_index(\"timestamp\").sort_index().resample(rule).apply(agg)\n",
    "    s = s.dropna(subset=[\"open\",\"high\",\"low\",\"close\"]).reset_index()\n",
    "    return s\n",
    "\n",
    "def _vol_scale_and_label(y: pd.Series | None):\n",
    "    if y is None or len(y)==0: return 1.0, \"units\"\n",
    "    m = float(np.nanmax(y))\n",
    "    if m >= 1e9: return 1e9, \"billions\"\n",
    "    if m >= 1e6: return 1e6, \"millions\"\n",
    "    if m >= 1e3: return 1e3, \"thousands\"\n",
    "    return 1.0, \"units\"\n",
    "\n",
    "def _make_price_panel(d: pd.DataFrame, *, title:str, chart_type:str,\n",
    "                      log_y:bool, show_ma:bool, ma_s:int, ma_l:int) -> go.Figure:\n",
    "    have_vol = \"volume\" in d.columns\n",
    "    vol_scale, vol_label = _vol_scale_and_label(d[\"volume\"] if have_vol else None)\n",
    "\n",
    "    # Hover text with OHLC values for candlesticks (Plotly 6 has no hovertemplate on Candlestick)\n",
    "    ohlc_text = [f\"O {o:.2f} | H {h:.2f} | L {l:.2f} | C {c:.2f}\"\n",
    "                 for o,h,l,c in zip(d[\"open\"], d[\"high\"], d[\"low\"], d[\"close\"])]\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
    "                        row_heights=[0.70, 0.30], vertical_spacing=0.06)\n",
    "\n",
    "    price_kw = dict(x=d[\"timestamp\"], open=d[\"open\"], high=d[\"high\"],\n",
    "                    low=d[\"low\"], close=d[\"close\"], name=\"OHLC\",\n",
    "                    increasing_line_color=\"#16a34a\", decreasing_line_color=\"#ef4444\")\n",
    "\n",
    "    if chart_type == \"ohlc\":\n",
    "        fig.add_trace(go.Ohlc(**price_kw), row=1, col=1)\n",
    "    else:\n",
    "        fig.add_trace(go.Candlestick(**price_kw, text=ohlc_text, hoverinfo=\"x+name+text\"),\n",
    "                      row=1, col=1)\n",
    "\n",
    "    if show_ma:\n",
    "        if ma_s>1: fig.add_trace(go.Scatter(x=d[\"timestamp\"], y=d[\"close\"].rolling(ma_s).mean(),\n",
    "                                            name=f\"MA{ma_s}\", mode=\"lines\",\n",
    "                                            line=dict(width=1.5, color=\"#3b82f6\")), row=1, col=1)\n",
    "        if ma_l>1: fig.add_trace(go.Scatter(x=d[\"timestamp\"], y=d[\"close\"].rolling(ma_l).mean(),\n",
    "                                            name=f\"MA{ma_l}\", mode=\"lines\",\n",
    "                                            line=dict(width=1.5, color=\"#f59e0b\")), row=1, col=1)\n",
    "\n",
    "    if have_vol:\n",
    "        up = d[\"close\"] >= d[\"open\"]\n",
    "        vol_colors = np.where(up, \"rgba(34, 197, 94, 0.45)\", \"rgba(239, 68, 68, 0.45)\")\n",
    "        fig.add_trace(go.Bar(x=d[\"timestamp\"], y=d[\"volume\"]/vol_scale,\n",
    "                             marker_color=vol_colors, name=f\"Volume ({vol_label})\"),\n",
    "                      row=2, col=1)\n",
    "\n",
    "    # Layout & interaction\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"x unified\",                 # single vertical hover line\n",
    "        legend=dict(orientation=\"h\", y=-0.18, x=0),  # keep clear of range buttons\n",
    "        margin=dict(l=50, r=30, t=60, b=80),\n",
    "        height=500,   # 👈 increase this number (default ~450)\n",
    "        xaxis_rangeslider_visible=True,\n",
    "        xaxis_rangeselector=dict(\n",
    "            buttons=[\n",
    "                dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"YTD\", step=\"year\",  stepmode=\"todate\"),\n",
    "                dict(count=1, label=\"1y\",  step=\"year\",  stepmode=\"backward\"),\n",
    "                dict(label=\"All\", step=\"all\"),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    fig.update_yaxes(title_text=\"price\", type=(\"log\" if log_y else \"linear\"), row=1, col=1)\n",
    "    fig.update_yaxes(title_text=f\"volume ({vol_label})\" if have_vol else \"volume\", row=2, col=1)\n",
    "\n",
    "    # nice hover spike\n",
    "    fig.update_xaxes(showspikes=True, spikemode=\"across\", spikesnap=\"cursor\",\n",
    "                     spikedash=\"dot\", spikethickness=1)\n",
    "    return fig\n",
    "\n",
    "# ---------- normalize inputs ----------\n",
    "df = _prep(df)\n",
    "bench_df = _prep(bench_df) if (\"bench_df\" in globals() and isinstance(bench_df, pd.DataFrame)) else None\n",
    "bench_symbol = globals().get(\"bench_symbol\",\"Benchmark\").upper()\n",
    "asset_label  = globals().get(\"symbol\",\"ASSET\").upper()\n",
    "\n",
    "# ---------- widgets ----------\n",
    "resample_dd = widgets.Dropdown(options=[(\"Original\",\"Original\"), (\"Weekly\",\"W\"), (\"Monthly\",\"M\")],\n",
    "                               value=\"Original\", description=\"Candles\", layout=widgets.Layout(width=\"210px\"))\n",
    "type_dd     = widgets.Dropdown(options=[(\"Candlestick\",\"candle\"), (\"OHLC\",\"ohlc\")],\n",
    "                               value=\"candle\", description=\"Type\", layout=widgets.Layout(width=\"210px\"))\n",
    "log_cb      = widgets.Checkbox(value=False, description=\"Log scale (y)\")\n",
    "show_ma_cb  = widgets.Checkbox(value=True, description=\"Show MAs\")\n",
    "ma_s_sl     = widgets.IntSlider(value=20, min=5, max=60, step=1, description=\"MA short\")\n",
    "ma_l_sl     = widgets.IntSlider(value=50, min=10, max=200, step=5, description=\"MA long\")\n",
    "sep_bench_cb= widgets.Checkbox(value=False, description=\"Separate benchmark figure\")\n",
    "bench_on_cb = widgets.Checkbox(value=(bench_df is not None), description=\"Use benchmark\")\n",
    "\n",
    "def _keep_ma_sensible(*_):\n",
    "    if ma_s_sl.value >= ma_l_sl.value:\n",
    "        ma_l_sl.value = max(ma_s_sl.value+5, ma_l_sl.value)\n",
    "ma_s_sl.observe(_keep_ma_sensible, \"value\")\n",
    "\n",
    "out_main  = widgets.Output()\n",
    "out_bench = widgets.Output()\n",
    "\n",
    "def _render(*_):\n",
    "    with out_main:\n",
    "        clear_output(wait=True)\n",
    "        base = _resample_ohlcv(df, resample_dd.value)\n",
    "        fig_main = _make_price_panel(\n",
    "            base,\n",
    "            title=f\"{asset_label} — Candlestick ({'Original' if resample_dd.value=='Original' else resample_dd.value})\",\n",
    "            chart_type=type_dd.value, log_y=log_cb.value,\n",
    "            show_ma=show_ma_cb.value, ma_s=ma_s_sl.value, ma_l=ma_l_sl.value\n",
    "        )\n",
    "\n",
    "        # overlay benchmark or not\n",
    "        if bench_on_cb.value and bench_df is not None and not sep_bench_cb.value:\n",
    "            b = _resample_ohlcv(bench_df, resample_dd.value)\n",
    "            merged = base[[\"timestamp\",\"close\"]].merge(\n",
    "                b[[\"timestamp\",\"close\"]].rename(columns={\"close\":\"bench\"}), on=\"timestamp\", how=\"inner\"\n",
    "            )\n",
    "            if not merged.empty:\n",
    "                # normalized line for fair comparison\n",
    "                idx = 100.0 * merged[\"bench\"] / merged[\"bench\"].iloc[0]\n",
    "                fig_main.add_trace(go.Scatter(x=merged[\"timestamp\"], y=idx,\n",
    "                                              name=bench_symbol, mode=\"lines\",\n",
    "                                              line=dict(width=1.8, color=\"#0ea5e9\")), row=1, col=1)\n",
    "                fig_main.update_yaxes(title_text=\"price / index (100)\", row=1, col=1)\n",
    "        fig_main.show(config={\"displaylogo\": False, \"toImageButtonOptions\": {\"format\": \"png\"}})\n",
    "\n",
    "    # separate benchmark figure (full chart) if requested\n",
    "    with out_bench:\n",
    "        clear_output(wait=True)\n",
    "        if bench_on_cb.value and bench_df is not None and sep_bench_cb.value:\n",
    "            b = _resample_ohlcv(bench_df, resample_dd.value)\n",
    "            fig_b = _make_price_panel(\n",
    "                b, title=f\"{bench_symbol} — Candlestick ({'Original' if resample_dd.value=='Original' else resample_dd.value})\",\n",
    "                chart_type=type_dd.value, log_y=log_cb.value,\n",
    "                show_ma=show_ma_cb.value, ma_s=ma_s_sl.value, ma_l=ma_l_sl.value\n",
    "            )\n",
    "            fig_b.show(config={\"displaylogo\": False, \"toImageButtonOptions\": {\"format\": \"png\"}})\n",
    "\n",
    "controls = widgets.VBox([\n",
    "    widgets.HBox([resample_dd, type_dd, log_cb]),\n",
    "    widgets.HBox([show_ma_cb, ma_s_sl, ma_l_sl]),\n",
    "    widgets.HBox([bench_on_cb, sep_bench_cb]),\n",
    "])\n",
    "\n",
    "for w in [resample_dd, type_dd, log_cb, show_ma_cb, ma_s_sl, ma_l_sl, bench_on_cb, sep_bench_cb]:\n",
    "    w.observe(_render, \"value\")\n",
    "\n",
    "display(controls, out_main, out_bench)\n",
    "_render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (quantAI)",
   "language": "python",
   "name": "quantai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
